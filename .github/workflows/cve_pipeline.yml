name: Kaggle CVE vulnerability enrichment automation pipeline

on:
    # Run automatically at 12:00 UTC every day
    schedule:
        - cron: '0 12 * * *'

    workflow_dispatch:
    # Run also when any of these files are updated using the main branch (for testing)
    push:
        branches: 
            - main
        paths:
            - 'extract2.py'
            - 'kaggle_manager.py'
            - 'requirements.txt'
            - '.github/workflows/cve_pipeline.yml'

jobs:
    # Job 1: Get all years from vulnrichment repo
    get-years:
      runs-on: ubuntu-latest

      outputs:
        years: ${{steps.get_years.outputs.years}}
      
      steps:
        # Step 1: Checkout repository
        - name: Check repository
          uses: actions/checkout@v4
          with: 
            fetch-depth: 0

        #Step 2: Setup pyhton
        - name: Set up Python
          uses: actions/setup-python@v4
          with: 
            python-version: '3.12.4'
            cache: 'pip'

        #Step 2.5: Installing dependencies from requirements file using pip
        - name: Install dependencies
          run: |
            pip install -r requirements.txt

        # Step 3: Get all years using extract2.py and set as output
        - name: Get all years
          env:
            GH_TOKEN: ${{ secrets.GH_TOKEN }}

          id: get_years
          run: |
            echo "years=$(python -c "from extract2 import cveExtractor; import json; print(json.dumps(cveExtractor().get_years()))")" >> "$GITHUB_OUTPUT"

    # Job 2: Extract CVEs and create datasets for each year
    extract-cves-and-create-dataset:
        needs: get-years

        runs-on: ubuntu-latest

        env:
          GH_TOKEN: ${{ secrets.GH_TOKEN }}

        strategy:
          matrix:
            #year: ${{ fromJson(needs.get-years.outputs.years) }}
            year: [2010, 2011]

        steps:
        #Step 1: Check out the repository 
        - name: Check repository
          uses: actions/checkout@v4
          with: 
            fetch-depth: 0

        #Step 2: Install python and it's dependencies using pip
        - name: Setup Python
          uses: actions/setup-python@v4
          with: 
            python-version: '3.12.4'
            cache: 'pip'

        # Step 2.5: Installing dependencies from requirements file using pip
        - name: Install dependencies
          run: |
            pip install -r requirements.txt

        # Step 3: Run cve extraction and csv creation from vulnerichment repo
        - name: Run CVE extraction from CISA vulnrichment repository for ${{ matrix.year }}
          run: |
            # First, check if GITHUB_TOKEN is set
            if [ -n ${{ secrets.GH_TOKEN }} ]; then
              echo "GITHUB_TOKEN is set"
              
            else
              echo "GITHUB_TOKEN is not set"
            fi

            # Second, start CVE extraction
            python extract2.py --year ${{ matrix.year}}
            echo 'CVE extraction completed for year ${{ matrix.year }}.'
          #Debug step
        - name: List dataset contents after extraction
          run: |
            ls -lh dataset/

        # Step 4: Artifacting the datasets for the ${{matrix.year}} year
        - name: Upload dataset csv for year
          uses: actions/upload-artifact@v4

          with:
            #This is the name of the artifact
            name: cve_data_${{ matrix.year  }}
            #This is the file that is uploaded as an artifact
            path: dataset/cve_data_${{ matrix.year }}.csv
    
    #Job 3: Creating a combined dataset from all artifacts
    create_combined_dataset:

      runs-on: ubuntu-latest

      needs:  extract-cves-and-create-dataset

      steps:
        #Step 1: Check out the repository 
        - name: Check repository
          uses: actions/checkout@v4
          with: 
            fetch-depth: 0

        #Step 2: Download all artifacts
        - name: Download artifacts
          uses: actions/download-artifact@v4
          with:
            pattern: cve_data_*
            path: dataset/artifacts

        - name: Find artifacts
          run: |
            ls  dataset/artifacts

        #Step 4: Combine all artifacts
        - name: Combine all artifacts
          run: |
            head -n 1 dataset/artifacts/cve_data_2011/cve_data_2011.csv> dataset/cve_data.csv
            tail -n +2 -q dataset/artifacts/cve_data_*/cve_data_*.csv >> dataset/cve_data.csv
            ls -lh dataset/cve_data.csv

        #Step 5: Artifact created combined dataset
        - name: Upload combined dataset artifact
          uses: actions/upload-artifact@v4
          with:
            name: cve_data_combined
            path: dataset/cve_data.csv

    upload-to-kaggle:
        needs: create_combined_dataset
        
        runs-on: ubuntu-latest

        env:
          KAGGLE_USERNAME: ${{ secrets.KAGGLE_USERNAME }}
          KAGGLE_KEY: ${{ secrets.KAGGLE_KEY }}

        steps:
          # Step 1: Check out the repository
          - name: Check repository
            uses: actions/checkout@v4
            with: 
              fetch-depth: 0
          
          # Step 2: Set up python 
          - name: Setup Python
            uses: actions/setup-python@v4
            with: 
              python-version: '3.12.4'
              cache: 'pip'

          #Step 2.5: Install dependencies using requirements.txt
          - name: Install dependencies
            run: |
              pip install -r requirements.txt

          #Step 3: Download combined dataset artifact
          - name: Download combined dataset artifact
            uses: actions/download-artifact@v4
            with:
              name: cve_data_combined
              path: dataset/

          # Step 3: Verify dataset file exists and upload to Kaggle
          - name: Verify and upload to kaggle
            run: |

              # Create a directory for Kaggle credentials
              mkdir --parents ~/.kaggle
              # Create a json file containing the Kaggle API credentials and copying to kaggle.json
              echo '{"username":"${{ secrets.KAGGLE_USERNAME }}","key":"${{ secrets.KAGGLE_KEY }}"}' > ~/.kaggle/kaggle.json
              #Setting directory permissions to r+w only 
              chmod 600 ~/.kaggle/kaggle.json

              # First, check if Kaggle credential env variables are set
              if [ -n ${{ secrets.KAGGLE_USERNAME }} ] && [ -n ${{ secrets.KAGGLE_KEY }} ]; then
                echo "Kaggle credentials are set"
                python kaggle_manager.py
              else
                echo "Kaggle credentials are not set"
                fi